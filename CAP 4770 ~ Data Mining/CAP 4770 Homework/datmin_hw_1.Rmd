---
title: "Homework Assignment 1"
subtitle: "Data Exploration and Preprocessing"
author: "Gus Lipkin - glipkin6737@floridapoly.edu"
output: html_notebook
---


> The **purpose** of this assignment is to:\
1.	Demonstrate proficiency in common tasks of an exploratory data analysis (EDA) \
2.	Practice methodologies for data preparation \
3.	Demonstrate understanding of relevant matrix decompositions and operations \

> **Course Learning Outcomes** (CLO) addressed in this assignment: \
1.	(CLO 1) Explain principles, concepts, methods, and techniques and trends in the fields of data mining, and knowledge discovery. \
2.	(CLO 2) Apply transformations to data, including discretization to numeric attributes, numeric coding of nominal attributes, data preprocessing and data cleansing techniques, and selection of appropriate features. \



## Problem 1

In this problem you are asked to find a research article related to one of the multiple topics described in the introductory lectures for this class, and discussed in our syllabus (e.g., association rule mining, outlier detection, sentiment analysis, topic modeling, etc.)

Do a search for one research article where a data mining and/or text mining methodology has been used in a field/application of you interest. Share the name of the paper, a short description of the main results (check the abstract and conclusions of the paper), and a direct link to the work.

You could use the University's library for this, or simply use Google Scholar for a list of the many papers that have used any of the techniques of interest in recent years.

> In [*Data Mining Customer and Employee-Related Subway Incidents*](http://csis.pace.edu/~ctappert/srd2009/d1.pdf), Budet et al. analyzed two databases that recorded incidents between MTA employees and customers. In both databases, the important information about the incidents was contained in the incident report comment field. They found that subway crime is "not an excessive problem". They also found that proper methodology and data collection is more helpful than data cleaning, even though all of them allow data mining.



## Problem 2

In this problem you will be using tools from the `caret` package (short for **C**lassification **A**nd **RE**gression **T**raining)

```{r}
# load the caret package
library(caret)
```

(a) Consider the data from the `mtcars` data frame (a built-in dataset in R): 

```{r}
# print the last 6 entries in the mtcars data frame
head(mtcars)
```


(b) Using tools from the `caret` package (discussed in class), perform the following transformations to the `mtcars` data frame: **normalization**, **standardization**, and **centering**.
```{r}
my_mtcars <- mtcars
# calculate the pre-process parameters from the dataset
preprocessParams_scale <- preProcess(my_mtcars, method = "scale")

# center
# calculate the pre-process parameters from the dataset
preprocessParams_center <- preProcess(my_mtcars, method = "center")
# transform the dataset using the parameters
transformed_center <- predict(preprocessParams_center, my_mtcars)
# summarize the transformed dataset
summary(transformed_center)

# standardize
# calculate the pre-process parameters from the dataset
preprocessParams_std <- preProcess(my_mtcars, method = c("scale", "center"))
# transform the dataset using the parameters
transformed_std <- predict(preprocessParams_std, my_mtcars)
# summarize the transformed dataset
summary(transformed_std)

# normalize
# calculate the pre-process parameters from the dataset
preprocess_norm <- preProcess(my_mtcars, method = "range")
# transform the dataset using the parameters
transformed_norm <- predict(preprocess_norm, my_mtcars)
# summarize the transformed dataset
summary(transformed_norm)
```


Comments on your results. Verify that in the standardization process, the transformed variables have _unit standard deviation_ (Hint: the `sd()` function in R computes the standard deviation). Choose 3 variables to confirm this. 
```{r}
sd(transformed_std$mpg)
sd(transformed_std$cyl)
sd(transformed_std$disp)
```



> _**Sample Product**_ \
- See solutions to the classwork activity `CW: normalization and standardization`

## Problem 3

The chunk of code below, defines a function in R to create a Hilbert matrix. 

```{r}
# create Hilbert matrix of size n 
hilbert <- function(n) { 
  i <- 1:n
  1 / outer(i - 1, i, "+") 
  }
```


(a) Build a Hilbert matrix of size 7, and call it `hil_seven`. 
```{r}
hil_seven <- hilbert(7)
```


(b) Select columns 1 through 4, and call it `X`
```{r}
X <- hil_seven[,1:4]
```


(c) Compute the **singular value decomposition** of `X` using the `svd()` function.
```{r}
svdX <- svd(X)
```


(d) Print the singular values of `X`
```{r}
svdX$d
```


(e) Verify that the product $U^T U$ where $U$ is the matrix of left singular values, returns the _identity matrix_ (a square matrix with ones in the main diagonal, and zeros everywhere else). Recall that the `t()` function in R, creates the _transpose_ of a matrix.
```{r}
t(svdX$u) %*% svdX$u
```



> _**Sample Product**_ \
- See solutions to the classwork activity `CW: Calculating the SVD of a matrix using R`


## Problem 4 

> This problem is mandatory for students in CAP 5771, optional for students in CAP 4770.


**Students in CAP 4770 receive 10 extra-credit points for solving this problem**


Go to page 125 of the textbook ["Mathematics for Machine Learning"](https://mml-book.github.io/book/mml-book.pdf), and recreate the SVD factorization of the matrix in Example 4.13 using tools from R. That is: 

- Find the **SVD factorization** of the matrix: 

$$
A = \begin{bmatrix}
1 & 0 & 1\\
-2 & 1 & 0
\end{bmatrix}
$$

> I tried my best here but could only replicate the first step

```{r}
ec <- matrix(c(1, -2, 0, 1, 1, 0), nrow = 2, ncol = 3)
svdEC <- svd(ec)

# step 1
ATA <- t(ec) %*% ec
D <- diag(ATA)


```


- Do you get the same **singular values**? 
> 

- What about the entries of the matrices of right and left singular values? Do you get the same entries?
> 



