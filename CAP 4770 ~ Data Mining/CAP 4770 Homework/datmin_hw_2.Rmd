---
title: "Homework Assignment 2"
subtitle: "Dimensionality Reduction using PCA"
author: "Gus Lipkin - glipkin6737@floridapoly.edu"
output: html_notebook
---


Load the `tidyverse` and `factoextra` packages for this assignment.

```{r, message = FALSE, warning=FALSE, comment=FALSE}
library(tidyverse)
library(factoextra)
```


# Problem 1 (25 points)

In this problem you are asked to find a recent research article that uses **Principal Component Analysis (PCA)** (or a variation of it).

Share:

- The name of the paper, authors, and affiliations.

- A short description of the main results (check the abstract and conclusions of the paper)

- A direct link to the work.

You could use the University's library for this, or simply use Google Scholar for a list of the many papers that have used this methodology in recent years.

> [Principal component analysis of urban traffic characteristics and meteorological data](https://www.sciencedirect.com/science/article/pii/S1361920903000063?casa_token=7BOZtJWu7HsAAAAA:GHDPsIW7TgUu_hmZz36G8DDpWpTXMvTHqJEjk1CNYbCQdvFfjHtMgu3Y8rIvEClgjiHnZIW-xg), written by S.M. Shiva Nagendra and Mukesh Khare from the Department of Civil Engineering, Indian Institute of Technology Delhi is about analyzing one-year traffic, emissions, and meteorological data for an intersection in urban Delhi. They found that PCA is a useful tool for large multivariate datasets and that traffic and emissions variables dominated the first principal component, independent of the time period length. The rest of the principal components were heavily focused on meteorological variables. Lastly, the found that traffic and emissions variables were weakly linked with the meteorological variables. 


# Problem 2 (25 points)

Consider the `USArrests` dataset, which contains statistics, in arrests per 100,000 residents for assault, murder, and rape in each of the 50 US states in 1973. Also given is the percent of the population living in urban areas.

```{r}
head(USArrests)
```

(a) Perform PCA on the four numerical variables in this dataset.

```{r}
arrests_pca <- prcomp(USArrests, scale. = T)
```


(b) Create a bi-plot (in the PC1-PC2 coordinate system) and explain your results. According to your findings: Do Florida, Nevada, California, and Michigan have anything in common? How about New Hampshire, Maine, and North Dakota?

```{r}
fviz_pca_biplot(arrests_pca, 
                select.ind = list(names = c("Florida", "Nevada", "California",
                                            "Michigan", "New Hampshire", "Maine",
                                            "North Dakota")))
```
> Comments: Maine and North Dakota have the most in common and are close to New Hampshire, while the other four states are similar in some respects but still quite different.


# Problem 3 (25 points)

In this problem you will use data from the [EA Sports FIFA 18](https://en.wikipedia.org/wiki/FIFA_18) videogame. 

- Get the dataset `fifa18.csv`: 

```{r, message=FALSE}
fifa18 <- read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/fifa18.csv", col_types = cols())
```

- Below is a sample of observations in this dataset:

```{r}
head(fifa18, 8)
```

(a) Use the numerical attributes in this dataset to perform PCA. Get a summary of your PCA results (use the `summary()` function as shown in examples). Comment on your results. 

```{r}
fifa18 <- fifa18[!duplicated(fifa18$name),]
# dataframe with only numerical attributes
myfifa18 <- select(fifa18, -c(1:3))
tibble::remove_rownames(myfifa18)
rownames(myfifa18) <- fifa18$name
```

> Extra comments: I had to engage in shenanigans here so that I could get player names to show up on the visualization. I just got rid of any rows where a player appeared a second or more time and then set the row names to the player names.

Perform PCA: 

```{r}
# code here - include as many chunks of code as needed
fifa_pca <- prcomp(myfifa18, scale. = T)
summary(fifa_pca)
```

> Comments: It's interesting how the amount of explanation by principal component tapers off. The first one is over 50%, then to get to 75% you need either 3 or 4 (depends if you're willing to round). To get to 90%, you need to go all the way out to PC9 and then to PC16 for 95%.



(b) Produce at least one **data visualization** to explain the results on PCA. (You can use the `factoextra` package for this and follow the examples discussed in class)

```{r}
# code here - include as many chunks of code as needed
fviz_pca_biplot(fifa_pca, 
                select.ind = list(name = c("Cristiano Ronaldo", "L. Messi", "Neymar", "Gus Outomouro", "Gus Ledes")))
fviz_contrib(fifa_pca, choice = "var", axes = 1)
fviz_contrib(fifa_pca, choice = "var", axes = 2)
```

> Comments: This was fun. The three names I know, Ronaldo, Messi, and Neymar, are all grouped together where I guess all the good players go. The two other players I've never heard of before that are named Gus share some similar properties, but not in such great quantities as the three well-known players.

> More Comments: Ball control and dribbling (I thought this was a function of ball control?) are the two most important parts. Compared to the second dimension, almost nothing is the same and it looks generally reversed.




# Problem 4 (25 points)

(a) Read the Toyota Corollas dataset on sales during late summer of 2004 in the Netherlands. It has 1436 records containing details on 38 attributes, including Price, Age, Kilometers, HP, and other specifications. 

```{r, message=FALSE}
toyota <- read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/ToyotaCorolla.csv", col_types = cols())
```


- Print the first 6 rows of the dataset.

```{r}
head(toyota)
```


- Identify (to the best of your knowledge) the categorical variables.

> Comments: `model`, `fuel_type`, and `color`. I'm not sure if indicator variables count, but if they do, `mfr_guarantee` and variables to the right.


(b) Create a new data frame with **some of the numerical attributes** in this dataset (ignoring the categorical variables, and think about which variables are probably categorical variables even when represented by a number). 

Perform **Principal Component Analysis (PCA)**, and **comment on your results**.

```{r}
# code here - include as many chunks of code as needed
# you could use the example above to select the collection of variables you want
myToyota <- toyota[,c("price", "age_08_04", "km", "hp", "quarterly_tax", "weight", "cc")]
toyota_pca <- prcomp(myToyota, scale. = T)
summary(toyota_pca)
```

> Comments: PC1 is only 40% of the variance which is a bit surprising to me. I'm not sure why that is. Getting 90% around PC4 seems a bit more standard to me. It also seems odd that there are seven principal components and seven variables.


(c) Produce at least one **data visualization** to explain the results on PCA. (You can use the `factoextra` package for this and follow the examples discussed in class)

```{r}
# code here - include as many chunks of code as needed
fviz_pca(toyota_pca, geom_ind = c("point", "text"), repel = TRUE, label = c("var", "ind"), habillage = factor(myToyota$hp))
```

> Comments: This is okay. There's general grouping by horsepower (the colors). It's a bit odd that there are no variables with arrows in the fourth quadrant.

## Problem 5 (20 points)

> **Required for graduate students**. _Extra-credit (+20 points) for undergraduate students_.

You will use data generated by the Spotify API on songs nominated to the _Grammy Award for Song of the Year_.

Find the data in this [GitHub repo](https://github.com/reisanar/datasets/blob/master/grammy_softy_20.csv), and read it into RStudio using:

```{r, message=FALSE}
# read grammy data
soty <- read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/grammy_softy_20.csv", col_types = cols())
rownames(soty) <- soty$track_name
head(soty)
```

(a) Perform PCA on this dataset, using all the **numerical attributes** available. 

```{r}
mySoty <- soty[, c(
    "danceability",
    "energy",
    "loudness",
    "speechiness",
    "acousticness",
    "instrumentalness",
    "liveness",
    "valence",
    "tempo",
    "duration_ms")]

soty_pca <- prcomp(mySoty, scale. = T)
```


(b) Summarize your findings and comment on your results. 

```{r}
summary(soty_pca)
```

> Comments: I'm not sure why I'm choosing 50% as a benchmark, but it's good to get it by PC2. 75% at PC4 seems alright with 90% at PC6. I'm not sure if there's any meaning behind my benchmarks being at 2, 4, and 6, but I also could've arbitrarily picked them so probably no meaning.

(c) Apply PCA again to a smaller number of numerical attributes (briefly explain your reasoning for the selection of the numerical attributes you consider for this part of the problem)

```{r}
mySoty <- mySoty[, c(
    "danceability",
    "energy",
    "loudness",
    "tempo")]

mySoty$danceability <- round(mySoty$danceability, 1)

soty_pca <- prcomp(mySoty[,-1], scale. = T)
summary(soty_pca)
```

> Comments: I selected `danceability`, `energy`, `loudness`, and `tempo` because I wanted to know if people in clubs really do enjoy loud music with good energy and good tempo. I did, however, decide to round the `danceability` to the tens place so that songs could be grouped a bit more neatly because no two songs had the same `danceability` score. I'm not sure how "legal" that is, but oh well. I then removed `danceability` so that it wouldn't affect the biplot.

(d) Create at least one data visualization of your PCA results.

```{r}
fviz_pca(soty_pca, geom_ind = c("point", "text"), repel = TRUE, label = c("var", "ind"), habillage = factor(mySoty$danceability))
```

> Comments: With my reduced set of variables, I wanted to see if there was a good grouping between songs with similar danceability scores. `fviz_pca` seems to fit the bill quite nicely because I can color code based on `danceabliity`. There seems to be no real color grouping except that songs with a `danceability` of $0.5$ are closer to the lines for `loudness`, `energy`, and `tempo` than the other groups.

